{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Digit Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense  # type: ignore\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid  # type: ignore\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.random.set_seed(1234)\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "In this project, we will build a neural network to recognize ten handwritten digits, `0-9`. This is a multiclass classification task where one of n choices is selected. Automated handwritten digit recognition is widely used today, from recognizing zip codes (postal codes) on mail envelopes to identifying amounts written on bank checks.\n",
    "\n",
    "## 2. Dataset\n",
    "\n",
    "We will start by loading the dataset for this task.\n",
    "\n",
    "- The first part of the training set is a 1000 x 400 dimensional vector `X` that contains the input features for the training set:\n",
    "    - Each training example is a 20x20 pixels grayscale image of the digit.\n",
    "    - Each pixel is represented by a `1` or a `0` number indicating the intensity at that location.\n",
    "    - The 20 by 20 grid of pixels is unrolled into a 400-dimensional vector.\n",
    "\n",
    "- The second part of the training set is a 1000 x 1 dimensional vector `y` that contains labels for the training set:\n",
    "    - `y = 0` if the image is of the digit `0`, `y = 4` if the image is of the digit `4` and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X, y = load_data() # _ * 400, _ * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Data\n",
    "\n",
    "Let's begin by visualizing a subset of the training set.\n",
    "\n",
    "In the cell below, the code randomly selects 64 rows from `X`, maps each row back to a 20x20 pixels grayscale image and displays the images together.\n",
    "\n",
    "The label for each image is displayed above the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "fig.tight_layout(pad=1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20))\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    ax.set_title(y[random_index])\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Representation\n",
    "\n",
    "The neural network we are building is shown in the figure below.\n",
    "\n",
    "This has the following structure:\n",
    "- Two dense layers with ReLU activations\n",
    "- An output layer with a linear activation\n",
    "\n",
    "<center>\n",
    "    <img src=\"./Images/model-representation.png\" alt=\"Model Representation\" height=\"300\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorFlow Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(400,)),  # type: ignore\n",
    "        Dense(units=25, activation=\"relu\", name=\"L1\"),\n",
    "        Dense(units=15, activation=\"relu\", name=\"L2\"),\n",
    "        Dense(units=10, activation=\"linear\", name=\"L3\"),\n",
    "    ],\n",
    "    name=\"ndv_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "[L1, L2, L3] = model.layers\n",
    "\n",
    "W1, b1 = L1.get_weights()\n",
    "W2, b2 = L2.get_weights()\n",
    "W3, b3 = L3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f\"W1 shape: {W1.shape}, b1 shape: {b1.shape}\")\n",
    "print(f\"W2 shape: {W2.shape}, b2 shape: {b2.shape}\")\n",
    "print(f\"W3 shape: {W3.shape}, b3 shape: {b3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # type: ignore\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # type: ignore\n",
    ")\n",
    "\n",
    "history = model.fit(X, y, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "model.save(\"ndv_model_200t.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL\n",
    "model = tf.keras.models.load_model(\"ndv_model_200t.keras\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "[L1, L2, L3] = model.layers\n",
    "\n",
    "W1, b1 = L1.get_weights()\n",
    "W2, b2 = L2.get_weights()\n",
    "W3, b3 = L3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf) # type: ignore\n",
    "\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot_loss_tf(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction \n",
    "To make a prediction, use Keras `predict`. Below, X[1015] contains an image of a two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHwAAAB8CAYAAACrHtS+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABgtJREFUeJztnc9LKl8UwI/6UCP6wUPSpEQXrVsERuuCVlF/Qe3cuIl2LaxNYBREJEHLdiktqj8ggjZZ0A9aBFEQIYiFi9SiEvQ+7uWbZPltHJvRO57zgctrfKOd5jPXc+/onGtijDEg0GBudABEfSHhyCDhyCDhyCDhyCDhyCDhyCDhyCDhyCDhyNBN+Pr6Oni9XrDb7TA4OAgnJyd6/SpCBSY9rqXHYjGYnJyEjY0NIXt1dRW2t7fh+voaurq6fnxusViEZDIJbW1tYDKZtA6tKeEKc7kcuN1uMJsV+jDTAb/fz4LBYGm7UCgwt9vNwuGw4nMTiQQ/AamB+saPnRKav6Xn83k4PT2FkZGR0mP8rOPbR0dH3/Z/f3+HbDZbavThXe3wd0UlNBeeTqehUCiA0+kse5xvp1Kpb/uHw2Ho6OgoNY/Ho3VIaDBVkQIbPkqfnZ2FTCZTaolEotEhNTV/tH5Bh8MBFosFHh4eyh7n2y6X69v+NptNNKI+aN7DrVYrDAwMwP7+ftnIm28PDQ1p/esItTAdiEajzGazsc3NTXZ1dcUCgQDr7OxkqVRK8bmZTKbho10waOPHTgldhHMikQjzeDzMarWKaVo8Hq/qeSQcdBWuy4WX38CnZny0rhfsF3+u7BeC+KC3vb1d7lE6UV9IODJIODI0n4cbDZNCXpZsiPNrqIcjg4Qjg4Qjg4Qjg4Qjg4Qjg4Qjg4Qjg4Qjg4QjA/2lVdZkl06VoB6ODBKODBKODHQ53KTya0rNluOphyODhCODhCMDXQ7HlrO/Qj0cGSQcGSQcGX+w5V2Tynm47LcXqYV6ODJUCz88PISxsTFRMYif/bu7u99629zcHHR3d0NLS4uo7XJzc6NlzEQ9hb+8vEB/f7+ow1aJpaUlWFtbEyW7jo+PobW1FUZHR+Ht7Q204r/bnEvtM/wk/Nx+81pNyW/uAedP39nZKW0Xi0XmcrnY8vJy6bGnpydRHGBra0uz+8OVYvppX1DxWpX2N/r94Zrm8Lu7O1Gp6XPJLn6vNy/OV6lkV6WyXbwR+qGp8I+yXNWW7KpUtqu3t1fLkAgjlu1SyrNa5myTyjGAltRjLKGp8I+yXNWW7OLwkl28TMXnRoAxhPt8PiH2c8kunpP5aJ1Kdhn0Stvz8zPc3t6WDdQuLi7g79+/omzm9PQ0LCwsQF9fnzgBQqGQmLNPTExoHTtRC0wlBwcHFacEU1NTpalZKBRiTqdTTMeGh4fZ9fV11a9faVr2ld9MXZSo5zRK6ziapmxXpYsrtcIU/tx6DtR+iqWWOKhsF/ENEo4MQ3w8+vXtTc1boUwZi0mQTqiHI4OEI4OEI8MQOVxNnlY7hWNf9m/WKeAH1MORQcKRQcKRYcgcrmUuNCnM27Wcx8vwlWfq4cgg4cgg4choihyuJSYJ8qyeUA9HBglHBglHBglHBglHBglHBglHBglHBglHBglHBglHBglHBglHhnTCZbpTxGhUc+ykE57L5RodgmGp5thJd7twsViEZDIpzlZeYIDXfJGtDEg2mxXFh2SJjR8rLpsXXjCbzcb6AgQPuKenp1S+S+a6L+0Sxfb1nnrDvKUT+kLCkSGtcF7Oa35+XvwrGzaJYzPcoI1A2sMJfSDhyCDhyCDhyJBWOF9xwev1gt1uF/XWT05O6h7DYRMu9yGl8FgsBjMzM2Lqc3Z2Jpbc4MtoPD4+1jWOFwmW+9AcJiF+v58Fg8HSdqFQYG63m4XD4YbFBDos99EIpOvh+XweTk9Py5bR4NfX+fb/LaPRCO5qWO5DBqQTnk6noVAoqFpGoxGkaljuQwakE04gE+5wOMBisahaRqMRuGpY7kMGpBNutVphYGCgbBkN/qUIvi3TMho+oy73wSQkGo2K0e7m5ia7urpigUCAdXZ2slQqVdc4crkcOz8/F40fqpWVFfHz/f29+P/FxUUR197eHru8vGTj4+PM5/Ox19dXJitSCudEIhHm8XiY1WoV07R4PF73GA50Xu6jEdDHo8iQLocT+kLCkUHCkUHCkUHCkUHCkUHCkUHCkUHCkUHCkUHCkUHCARf/ACGZthcjPXkgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "Predicting a 'Two': [[ 6.76 -5.55  8.7  -2.58  6.46  1.12  5.57  1.99 -5.52 -9.63]]\n",
      "Largest prediction index: 2\n"
     ]
    }
   ],
   "source": [
    "# image_of_seven = X[0]\n",
    "\n",
    "image_of_two = np.array(\n",
    "    [\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "\n",
    "display_digit(image_of_two)\n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1, 400))\n",
    "\n",
    "print(f\"Predicting a 'Two': {prediction}\")\n",
    "print(f\"Largest prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest output is prediction[2], indicating the predicted digit is a '2'. If the problem only requires a selection, that is sufficient. Use NumPy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) to select it. If the problem requires a probability, a softmax is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "prediction_prb = tf.nn.softmax(prediction)\n",
    "probabilities = \" \".join([f\"{prob:2.3f}\" for prob in prediction_prb[0]])\n",
    "\n",
    "print(f\"Predicting a 'Seven' probability vector: {probabilities}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_prb):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "yhat = np.argmax(prediction_prb)\n",
    "print(f\"np.argmax(prediction_prb): {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the predictions `vs` the labels for a random sample of 8 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "fig.tight_layout(pad=1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20))\n",
    "\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    prediction = model.predict(X[random_index].reshape(1, 400))\n",
    "    prediction_prb = tf.nn.softmax(prediction)\n",
    "    yhat = np.argmax(prediction_prb)\n",
    "\n",
    "    ax.set_title(f\"{y[random_index]}, {yhat} -> {np.max(prediction_prb)*100:2.3f}%\", fontsize=10)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f\"{display_errors(model, X, y, True)} errors out of {len(X)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "TFVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
